{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMe32+Ly0ua8GCuhBHrqyf9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TWaugh12/Projects/blob/main/SpamTextClassifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qsBXharzO0ei"
      },
      "outputs": [],
      "source": [
        "import urllib.request, zipfile, io\n",
        "import re\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from collections import Counter\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def download_and_unzip(url, extract_to='.'):\n",
        "  with urllib.request.urlopen(url) as response:\n",
        "    file_content = response.read()\n",
        "    zip_file_like = io.BytesIO(file_content)\n",
        "\n",
        "  with zipfile.ZipFile(zip_file_like) as zip_file:\n",
        "    zip_file.extractall(extract_to)\n",
        "\n",
        "# File containts text messages, first word is either 'spam' or 'ham' which classifies text as spam or not\n",
        "\n",
        "download_and_unzip(url='https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip', extract_to='.')\n",
        "\n",
        "\n",
        "\n",
        "# Load and prepare data. Lower case, no punctuation.\n",
        "data = [ln.strip() for ln in open('./SMSSpamCollection')]\n",
        "data = [re.sub('[^A-Za-z0-9]+', ' ', line).lower() for line in data]\n",
        "data = [re.sub(' +', ' ', line) for line in data]"
      ],
      "metadata": {
        "id": "9LyyXLICJOf2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into training and testing\n",
        "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "# Create a vocabulary\n",
        "words = [word for line in data for word in line.split()]\n",
        "word_counts = Counter(words)\n",
        "vocab = [word for word, count in word_counts.most_common(10000)]\n",
        "\n",
        "# Add /UNK and /PAD tokens\n",
        "vocab.extend([\"/UNK\", \"/PAD\"])\n",
        "\n",
        "# Create a dictionary for word to index mapping\n",
        "vocabulary = {word: idx for idx, word in enumerate(vocab)}\n",
        "\n",
        "print(\"Vocabulary size:\", len(vocabulary))\n",
        "print(\"Train length:\", len(train_data))\n",
        "print(\"Test length:\", len(test_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qw50bCMiPP03",
        "outputId": "aaf85cd7-0c1a-43d7-b7cc-1ff0fcd0f45d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size: 8747\n",
            "Train length: 4459\n",
            "Test length: 1115\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SMSDataset(Dataset):\n",
        "    def __init__(self, data, vocab):\n",
        "        self.data = data\n",
        "        self.vocab = vocab\n",
        "        self.spam_count = 0\n",
        "        self.ham_count = 0\n",
        "\n",
        "        # Count spam and ham messages\n",
        "        for line in self.data:\n",
        "            label, _ = line.split(' ', 1)\n",
        "            if label.lower() == 'spam':\n",
        "                self.spam_count += 1\n",
        "            else:\n",
        "                self.ham_count += 1\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Extracting the message and its label\n",
        "        line = self.data[idx]\n",
        "        label, message = line.split(' ', 1)\n",
        "\n",
        "        # Converting label to integer (1 for spam, 0 for ham)\n",
        "        label = 1 if label.lower() == 'spam' else 0\n",
        "\n",
        "        # Preprocessing the message\n",
        "        processed_message = self.preprocess_message(message)\n",
        "\n",
        "        return torch.tensor(processed_message, dtype=torch.long), torch.tensor(label, dtype=torch.long)\n",
        "\n",
        "    def preprocess_message(self, message):\n",
        "        # Splitting into words\n",
        "        words = message.split()\n",
        "\n",
        "        # Truncating if length > 30\n",
        "        if len(words) > 30:\n",
        "            words = words[:30]\n",
        "\n",
        "        # Padding with '/PAD' if length < 30\n",
        "        elif len(words) < 30:\n",
        "            pad_length = 30 - len(words)\n",
        "            words = ['/PAD'] * pad_length + words\n",
        "\n",
        "        # Converting words to indices\n",
        "        indices = [self.vocab.get(word, self.vocab['/UNK']) for word in words]\n",
        "\n",
        "        return indices\n",
        "\n",
        "\n",
        "train_dataset = SMSDataset(train_data, vocabulary)\n",
        "test_dataset = SMSDataset(test_data, vocabulary)"
      ],
      "metadata": {
        "id": "-f7KlNQbjQe2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SpamRNN(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim):\n",
        "        super().__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        # Embedding layer\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        # RNN-like layers\n",
        "        self.inp2state = nn.Linear(embedding_dim, hidden_dim)\n",
        "        self.state2state = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.state2out = nn.Linear(hidden_dim, 1)\n",
        "\n",
        "        # Initialize weights\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.normal_(m.weight, std=0.01)\n",
        "                nn.init.zeros_(m.bias)\n",
        "\n",
        "    def initial_state(self, batch_size, device):\n",
        "        return torch.zeros((batch_size, self.hidden_dim)).to(device)\n",
        "\n",
        "    def forward(self, sequence):\n",
        "        # Embedding\n",
        "        embedded = self.embedding(sequence)\n",
        "\n",
        "        # Average embeddings\n",
        "        avg_embedding = torch.mean(embedded, dim=1)\n",
        "\n",
        "        # Compute state\n",
        "        state = self.initial_state(sequence.size(0), sequence.device)\n",
        "        state = torch.tanh(self.inp2state(avg_embedding) + self.state2state(state))\n",
        "\n",
        "        # Output\n",
        "        output = torch.sigmoid(self.state2out(state))\n",
        "        return output\n",
        "\n",
        "\n",
        "# Define the model\n",
        "vocab_size = len(vocabulary)\n",
        "embedding_dim = 128\n",
        "model = SpamRNN(vocab_size, embedding_dim, hidden_dim=256)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQY6ZbWxl4LZ",
        "outputId": "5f4ab1a5-99b8-4e01-b00b-75524aa11b81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SpamRNN(\n",
            "  (embedding): Embedding(8747, 128)\n",
            "  (inp2state): Linear(in_features=128, out_features=256, bias=True)\n",
            "  (state2state): Linear(in_features=256, out_features=256, bias=True)\n",
            "  (state2out): Linear(in_features=256, out_features=1, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "learning_rate = 0.001\n",
        "epochs = 20\n",
        "batch_size = 100\n",
        "optimizer = torch.optim.Adam(model.parameters(), learning_rate)\n",
        "train_loader = DataLoader(train_dataset, batch_size = 32, shuffle = True)\n",
        "test_loader = DataLoader(test_dataset, batch_size = 32, shuffle = True)\n",
        "criterion = nn.BCEWithLogitsLoss()"
      ],
      "metadata": {
        "id": "tBKTQ9YouGiX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_accuracy(loader, model):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in loader:\n",
        "            inputs, labels = inputs.long(), labels.long()\n",
        "            outputs = model(inputs)\n",
        "            predicted = (outputs > 0.5).float()\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted.squeeze() == labels).sum().item()\n",
        "    return 100 * correct / total\n",
        "\n",
        "# Training Loop\n",
        "for epoch in range(20):\n",
        "    model.train()\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.long(), labels.long()\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels.unsqueeze(1).float())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    train_acc = calculate_accuracy(train_loader, model)\n",
        "    test_acc = calculate_accuracy(test_loader, model)\n",
        "    print(f'Epoch [{epoch+1}/20], Loss: {loss.item():.4f}, Train Acc: {train_acc:.2f}%, Test Acc: {test_acc:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWG50_9Axwzw",
        "outputId": "c1bc5554-a35d-4290-8622-72b6f6cae959"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/20], Loss: 0.6623, Train Acc: 96.46%, Test Acc: 96.41%\n",
            "Epoch [2/20], Loss: 0.6251, Train Acc: 98.23%, Test Acc: 97.76%\n",
            "Epoch [3/20], Loss: 0.6242, Train Acc: 98.79%, Test Acc: 98.12%\n",
            "Epoch [4/20], Loss: 0.6595, Train Acc: 98.95%, Test Acc: 98.12%\n",
            "Epoch [5/20], Loss: 0.6241, Train Acc: 99.01%, Test Acc: 98.12%\n",
            "Epoch [6/20], Loss: 0.6243, Train Acc: 99.22%, Test Acc: 98.21%\n",
            "Epoch [7/20], Loss: 0.6587, Train Acc: 99.37%, Test Acc: 98.83%\n",
            "Epoch [8/20], Loss: 0.5896, Train Acc: 99.37%, Test Acc: 98.65%\n",
            "Epoch [9/20], Loss: 0.6931, Train Acc: 99.37%, Test Acc: 98.48%\n",
            "Epoch [10/20], Loss: 0.6241, Train Acc: 99.26%, Test Acc: 98.39%\n",
            "Epoch [11/20], Loss: 0.6586, Train Acc: 99.39%, Test Acc: 98.39%\n",
            "Epoch [12/20], Loss: 0.5896, Train Acc: 99.51%, Test Acc: 98.65%\n",
            "Epoch [13/20], Loss: 0.6618, Train Acc: 99.51%, Test Acc: 98.74%\n",
            "Epoch [14/20], Loss: 0.6241, Train Acc: 99.51%, Test Acc: 98.74%\n",
            "Epoch [15/20], Loss: 0.6586, Train Acc: 99.51%, Test Acc: 98.74%\n",
            "Epoch [16/20], Loss: 0.6584, Train Acc: 99.51%, Test Acc: 98.65%\n",
            "Epoch [17/20], Loss: 0.6241, Train Acc: 99.51%, Test Acc: 98.57%\n",
            "Epoch [18/20], Loss: 0.6932, Train Acc: 99.53%, Test Acc: 98.65%\n",
            "Epoch [19/20], Loss: 0.6586, Train Acc: 99.55%, Test Acc: 98.57%\n",
            "Epoch [20/20], Loss: 0.5895, Train Acc: 99.57%, Test Acc: 98.65%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inverse_vocab = {idx: word for word, idx in vocabulary.items()}\n",
        "\n",
        "def sms_from_indices(indices):\n",
        "    return ' '.join([inverse_vocab.get(idx, '/UNK') for idx in indices])\n",
        "\n",
        "\n",
        "# Move the model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Processing the first 10 messages from the test set\n",
        "with torch.no_grad():\n",
        "    for i, (inputs, labels) in enumerate(test_loader):\n",
        "        if i >= 10:\n",
        "            break\n",
        "        inputs = inputs.long()\n",
        "        outputs = model(inputs)\n",
        "        predicted = (outputs > 0.5).squeeze().long()\n",
        "\n",
        "        for j in range(inputs.size(0)):\n",
        "            if i * batch_size + j >= 10:\n",
        "                break\n",
        "            sms_text = sms_from_indices(inputs[j].tolist())\n",
        "            print(f\"SMS: {sms_text}\")\n",
        "            print(f\"Prediction: {'Spam' if predicted[j].item() == 1 else 'Ham'}\")\n",
        "            print(f\"Ground Truth: {'Spam' if labels[j].item() == 1 else 'Ham'}\")\n",
        "            print(\"-----\")"
      ],
      "metadata": {
        "id": "oFGfhjSk60_T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e278a81f-a380-4477-b8b4-92fd17d935f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SMS: /PAD /PAD /PAD which is why i never wanted to tell you any of this which is why i m so short with you and on edge as of late\n",
            "Prediction: Ham\n",
            "Ground Truth: Ham\n",
            "-----\n",
            "SMS: /PAD /PAD /PAD /PAD /PAD /PAD /PAD /PAD /PAD /PAD /PAD /PAD /PAD /PAD /PAD /PAD /PAD /PAD /PAD /PAD /PAD /PAD /PAD /PAD /PAD /PAD /PAD huh y lei\n",
            "Prediction: Ham\n",
            "Ground Truth: Ham\n",
            "-----\n",
            "SMS: /PAD /PAD /PAD /PAD /PAD /PAD /PAD /PAD /PAD /PAD /PAD /PAD me too baby i promise to treat you well i bet you will take good care of me\n",
            "Prediction: Ham\n",
            "Ground Truth: Ham\n",
            "-----\n",
            "SMS: /PAD /PAD thanks for being there for me just to talk to on saturday you are very dear to me i cherish having you as a brother and role model\n",
            "Prediction: Ham\n",
            "Ground Truth: Ham\n",
            "-----\n",
            "SMS: /PAD /PAD /PAD /PAD /PAD /PAD /PAD /PAD /PAD /PAD /PAD /PAD /PAD /PAD /PAD /PAD /PAD /PAD /PAD /PAD /PAD /PAD /PAD /PAD yo im right by yo work\n",
            "Prediction: Ham\n",
            "Ground Truth: Ham\n",
            "-----\n",
            "SMS: warner village 83118 c colin farrell in swat this wkend warner village get 1 free med popcorn just show msg ticket kiosk valid 4 7 12 c t c kiosk\n",
            "Prediction: Spam\n",
            "Ground Truth: Spam\n",
            "-----\n",
            "SMS: /PAD /PAD /PAD /PAD /PAD /PAD /PAD /PAD /PAD /PAD /PAD /PAD /PAD /PAD /PAD /PAD /PAD /PAD /PAD /PAD /PAD /PAD /PAD /PAD /PAD /PAD your pussy is perfect\n",
            "Prediction: Ham\n",
            "Ground Truth: Ham\n",
            "-----\n",
            "SMS: /PAD /PAD /PAD /PAD /PAD /PAD /PAD /PAD /PAD /PAD /PAD /PAD /PAD /PAD /PAD /PAD /PAD /PAD /PAD /PAD /PAD /PAD dude how do you like the buff wind\n",
            "Prediction: Ham\n",
            "Ground Truth: Ham\n",
            "-----\n",
            "SMS: /PAD /PAD /PAD /PAD /PAD /PAD /PAD /PAD /PAD /PAD /PAD /PAD /PAD /PAD helloooo wake up sweet morning welcomes you enjoy this day with full of joy gud mrng\n",
            "Prediction: Ham\n",
            "Ground Truth: Ham\n",
            "-----\n",
            "SMS: /PAD /PAD /PAD /PAD /PAD /PAD /PAD /PAD /PAD /PAD /PAD /PAD /PAD /PAD /PAD x course it 2yrs just so her messages on messenger lik you r sending me\n",
            "Prediction: Ham\n",
            "Ground Truth: Ham\n",
            "-----\n"
          ]
        }
      ]
    }
  ]
}
